{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Event Lip Reading\n",
    "\n",
    "**Author**: Adly Zaroui\n",
    "\n",
    "The \"Event Lip Reading\" project aims to develop a system that can recognize and interpret lip movements from event-based sensor data. Event-based sensors are capable of capturing high-frequency changes in luminosity, making them ideal for applications that require a high refresh rate. In this project, the event data consists of tuples containing the pixel coordinates, polarity (increase or decrease in luminosity), and timestamp of each event.\n",
    "\n",
    "The goal of the project is to classify these events and extract meaningful information from them. This can be achieved by aggregating the events into superframes, converting them into images, and applying various image processing techniques. The project involves tasks such as loading the event data, converting events to images, creating animations from the images, and aggregating events into superframes.\n",
    "\n",
    "By analyzing the lip movements captured by the event-based sensor, the system can potentially be used for lip reading applications, speech recognition, and other related tasks. The project utilizes Python, pandas, numpy, matplotlib, and other libraries to process and visualize the event data.\n",
    "\n",
    "To analyze event data, there is mainly 2 ways: the first one is to convert the events into conventional video data (sequence of images - sequence of matrices of pixels values) then apply conventional video classification algorithms. The first path that we will dive into is to treat event data as they are: multivariate time series, then explore classification techniques on mulitvariate time series.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's define a function that loads the data and then use it to load he data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm # for tracking progress\n",
    "\n",
    "def load_data(base_path, class_folders=None):\n",
    "    '''\n",
    "    Loads the data from the specified base path.\n",
    "    \n",
    "    Parameters:\n",
    "        base_path (str): The base path to the data.\n",
    "        class_folders (list): The list of class folders names to load, or None to load all.\n",
    "        \n",
    "    Returns:\n",
    "        dataframes (list): A list of dataframes.\n",
    "    '''\n",
    "    \n",
    "    # Initialize a list to hold dataframes\n",
    "    dataframes = []\n",
    "\n",
    "    if class_folders:\n",
    "        # Loop over each class folder\n",
    "        for folder in tqdm(class_folders):\n",
    "            # Get the list of CSV files in this class folder\n",
    "            csv_files = os.listdir(os.path.join(base_path, folder))\n",
    "            \n",
    "            # Loop over each CSV file\n",
    "            for csv_file in csv_files:\n",
    "                # Define the full path to the CSV file\n",
    "                csv_path = os.path.join(base_path, folder, csv_file)\n",
    "                \n",
    "                # Load the CSV file into a dataframe\n",
    "                df = pd.read_csv(csv_path)\n",
    "                \n",
    "                # Append the dataframe to the list\n",
    "                dataframes.append(df)\n",
    "    else:\n",
    "        # Get the list of CSV files in the base path\n",
    "        csv_files = os.listdir(base_path)\n",
    "\n",
    "        # Loop over each CSV file\n",
    "        for csv_file in tqdm(csv_files):\n",
    "            # Define the full path to the CSV file\n",
    "            csv_path = os.path.join(base_path, csv_file)\n",
    "            \n",
    "            # Load the CSV file into a dataframe\n",
    "            df = pd.read_csv(csv_path)\n",
    "            \n",
    "            # Append the dataframe to the list\n",
    "            dataframes.append(df)\n",
    "\n",
    "    return dataframes\n",
    "\n",
    "# Define the base paths\n",
    "train_base_path = 'train10/train10/'\n",
    "test_base_path = '/test10/test10/'\n",
    "\n",
    "# Define the class folders\n",
    "class_folders = ['Addition', 'Carnaval', 'Decider', 'Ecole', 'Fillette', 'Huitre', 'Joyeux', 'Musique', 'Pyjama', 'Ruisseau']\n",
    "\n",
    "# Load the training and test data\n",
    "x_train = load_data(train_base_path, class_folders)\n",
    "#x_test = load_data(test_base_path)\n",
    "\n",
    "# Create target data\n",
    "y_train = []\n",
    "for i, class_name in enumerate(class_folders):\n",
    "    y_train.extend([i] * len(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "***\n",
    "Now let's define a function to plot an image from an event dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def events_to_image(df, x_max=640, y_max=480):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Converts a dataframe of events to a 2D image taht is a 2D histogram of the events.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): A dataframe of events.\n",
    "        x_max (int): The maximum x coordinate, defaults to 100.\n",
    "        y_max (int): The maximum y coordinate, defaults to 100.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: A 2D image.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    from scipy.ndimage import rotate\n",
    "    \n",
    "    # Create a 2D histogram of the event data\n",
    "    hist, _, _ = np.histogram2d(df['x'], df['y'], bins=[x_max, y_max], weights=df['polarity'])\n",
    "\n",
    "    # Normalize the histogram to the range [0, 255]\n",
    "    hist = 255 * (hist - np.min(hist)) / (np.max(hist) - np.min(hist))\n",
    "    \n",
    "    hist = rotate(hist, 225)\n",
    "\n",
    "    return hist.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_event_df = x_train[0]\n",
    "test_images = events_to_image(test_event_df)\n",
    "\n",
    "# Display an example image\n",
    "plt.imshow(test_images, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Now let's define some functions convert an event dataframe into a sequence of images, incrisignly *w.r.t.* timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_agg(x, y, polarity, timestamp, T_r=100000, M=640, N=480):\n",
    "    '''\n",
    "    Aggregate events into superframes.\n",
    "    \n",
    "    Args:\n",
    "        x (np.array): x coordinates of events\n",
    "        y (np.array): y coordinates of events\n",
    "        polarity (np.array): polarity of events\n",
    "        timestamp (np.array): timestamp of events\n",
    "        T_r (float): time interval of superframes, defaults to 100000.\n",
    "        M (int): image length, defaults to 640.\n",
    "        N (int): image width, defaults to 480.\n",
    "        \n",
    "    Returns:\n",
    "        superframes (np.array): superframes\n",
    "    '''\n",
    "    \n",
    "    from scipy.ndimage import rotate\n",
    "    \n",
    "    T_seq = timestamp.max()\n",
    "    T_frames = int((T_seq // T_r)) + 1\n",
    "    \n",
    "    frames_0 = np.zeros((T_frames, M, N)) # polarity == 0\n",
    "    frames_1 = np.zeros((T_frames, M, N)) # polarity == 1\n",
    "    \n",
    "    for i in tqdm(range(T_frames)):\n",
    "        idx_0 = np.where((timestamp >= i * T_r) & (timestamp < (i+1) * T_r) & (polarity == 0))[0]\n",
    "        if len(idx_0) > 0:\n",
    "            frames_0[i] = np.bincount(N * x[idx_0] + y[idx_0], minlength = M * N).reshape(M, N)\n",
    "        \n",
    "        idx_1 = np.where((timestamp >= i * T_r) & (timestamp < (i+1) * T_r) & (polarity == 1))[0]\n",
    "        if len(idx_1) > 0:\n",
    "            frames_1[i] = np.bincount(N * x[idx_1] + y[idx_1], minlength = M * N).reshape(M, N)\n",
    "    \n",
    "    # Rotate the frames\n",
    "    frames_0 = rotate(frames_0, 225, axes=(1,2), reshape=False)\n",
    "    frames_1 = rotate(frames_1, 225, axes=(1,2), reshape=False)\n",
    "    \n",
    "    superframes = np.concatenate((frames_0, frames_1), axis = 0)\n",
    "    print('generated superframes with size:', superframes.shape)\n",
    "    return superframes\n",
    "    \n",
    "def decompose_events(test_data):\n",
    "    '''\n",
    "    \n",
    "    Decompose the events dataframe into tuple of individual columns x, y, polarity, and timestamp.\n",
    "    \n",
    "    Args:\n",
    "        test_data (pd.DataFrame): A dataframe of events.\n",
    "        \n",
    "    Returns:\n",
    "        4-tuple: x (np.array): x coordinates of events,\n",
    "                 y (np.array): y coordinates of events,\n",
    "                 polarity (np.array): polarity of events,\n",
    "                 timestamp (np.array): timestamp of events  \n",
    "    '''\n",
    "    \n",
    "    return (np.array(test_data['x'].values),\n",
    "            np.array(test_data['y'].values),\n",
    "            np.array(test_data['polarity'].values),\n",
    "            np.array(test_data['time'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Define the superframes '''\n",
    "\n",
    "test_event_df = train_data['Addition'][0]\n",
    "\n",
    "x, y, polarity, timestamp = decompose_events(test_event_df)\n",
    "\n",
    "superframes = event_agg(x, y, polarity, timestamp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Watch the superframes '''\n",
    "    \n",
    "from matplotlib import cm\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "    \n",
    "frames = [] # for storing the generated images\n",
    "fig = plt.figure()\n",
    "for i in range(superframes.shape[0]):\n",
    "    frames.append([plt.imshow(superframes[i], cmap = cm.Greys_r, animated = True)])\n",
    "\n",
    "ani = animation.ArtistAnimation(fig, frames, interval = 50, blit = False, repeat_delay = 1000)\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "window_size = 5 # window size for smoothing\n",
    "# Denoise and compute statistics for each DataFrame\n",
    "flat_agg_x_train = []\n",
    "for key in x_train:\n",
    "    for event_df in x_train[key]:\n",
    "        event_df_smooth = event_df.rolling(window_size).mean().dropna()\n",
    "\n",
    "        stats = event_df_smooth.agg(['mean', 'std', 'max', 'min', 'skew', 'kurt', 'median', 'sem'])\n",
    "        flat_agg_x_train.append(stats.values.flatten())\n",
    "        \n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(flat_agg_x_train)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=0.95)  # Keep 95% of variance\n",
    "pca_x_train = pca.fit_transform(x_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "# Create a scatter plot of the first two principal components\n",
    "scatter = plt.scatter(pca_x_train[:, 0], pca_x_train[:, 1], c=y_train, cmap=cm.Set1)\n",
    "\n",
    "# Add a colorbar\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label('Classes')\n",
    "\n",
    "# Add a title and labels\n",
    "plt.title('PCA of x_train')\n",
    "plt.xlabel('First Principal Component')\n",
    "plt.ylabel('Second Principal Component')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
